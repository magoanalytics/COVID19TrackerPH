{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "\n",
    "def get_mb():\n",
    "    try:\n",
    "        mb_ncov_news = []\n",
    "        user_agent = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0)'\n",
    "\n",
    "\n",
    "        req = Request('https://news.mb.com.ph/tag/ncov', headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "                    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "                    'Accept-Encoding': 'none',\n",
    "                    'Accept-Language': 'en-US,en;q=0.8',\n",
    "                    'Connection': 'keep-alive'})\n",
    "\n",
    "\n",
    "        content = urlopen(req).read()\n",
    "\n",
    "        #print('reading url')\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "        last_page = int(soup.find(\"ul\", {'class':\"uk-pagination\"}).text[-3:]) + 1  \n",
    "        \n",
    "        df_list = pd.read_csv('mb_ncov_articles_urls.csv', header = None)\n",
    "        article_list = df_list[0]\n",
    "        \n",
    "        loop = True\n",
    "        \n",
    "        print('start')\n",
    "        for i in range(1, last_page):\n",
    "\n",
    "            page_link = 'https://news.mb.com.ph/tag/ncov/page' + str(i) + '/'\n",
    "            print(page_link)\n",
    "            req = Request(page_link, headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "                    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "                    'Accept-Encoding': 'none',\n",
    "                    'Accept-Language': 'en-US,en;q=0.8',\n",
    "                    'Connection': 'keep-alive'})\n",
    "\n",
    "            content = urlopen(req).read()\n",
    "\n",
    "            #print('reading url')\n",
    "            soup = BeautifulSoup(content)\n",
    "\n",
    "            #print('reading main news section')\n",
    "            mydivs = soup.find(\"main\", {'class':\"tm-content\"})\n",
    "\n",
    "            #print('reading urls in news section')\n",
    "            mydivs = mydivs.find_all(\"article\", {'class':\"uk-article listwiththumb\"})\n",
    "            \n",
    "            for url in mydivs:\n",
    "                #print(url.a['href'])\n",
    "                if url.a['href'] in article_list.values:\n",
    "                    loop = False\n",
    "                    print(url.a['href'] + ' stopped latest')\n",
    "                    break\n",
    "                else:\n",
    "                    mb_ncov_news.append(url.a['href'])\n",
    "            \n",
    "            if loop == False:\n",
    "                break\n",
    "            #mb_ncov_news += [url.a['href'] for url in mydivs]\n",
    "\n",
    "            #print(i)\n",
    "            #print(len(mb_ncov_news))\n",
    "            time.sleep(1)\n",
    "\n",
    "        to_add = pd.Series(mb_ncov_news)\n",
    "        #f['articles'] = article_list.append(to_add).reset_index(drop = True)\n",
    "        #df.to_csv('new_mb_ncov_articles.csv', index = False)\n",
    "        \n",
    "        mb_df = pd.DataFrame(columns = ['source_id','date','category','title','author','text'])\n",
    "        df = pd.read_csv('mb_scraped.csv')\n",
    "        \n",
    "        print(len(mb_ncov_news))\n",
    "        \n",
    "        for article in mb_ncov_news:  \n",
    "            user_agent = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) '\n",
    "            req = Request(article, headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "                    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "                    'Accept-Encoding': 'none',\n",
    "                    'Accept-Language': 'en-US,en;q=0.8',\n",
    "                    'Connection': 'keep-alive'})\n",
    "            content = urlopen(req).read()\n",
    "            soup = BeautifulSoup(content)\n",
    "\n",
    "            try:\n",
    "                article_id = ''\n",
    "                date = soup.find('time').text\n",
    "                category = 'nCov'\n",
    "                title = soup.find(\"h1\", {'class':\"uk-article-title uk-margin-bottom-remove\"}).text\n",
    "                author = soup.find('strong').text\n",
    "                art = soup.find_all(\"p\")\n",
    "                text = ' '.join(item.text for item in art)\n",
    "            except AttributeError:\n",
    "                continue\n",
    "\n",
    "            print(title, date)\n",
    "            mb_df = mb_df.append(pd.Series([article_id,date,category, title,author, text], index = mb_df.columns ), ignore_index=True)\n",
    "            time.sleep(3)\n",
    "\n",
    "        df = df.append(mb_df)\n",
    "        df.to_csv('mb_scraped.csv', index = False)\n",
    "        \n",
    "        df_list[0].append(to_add).reset_index(drop = True).to_csv('mb_ncov_articles_urls.csv', index = False)\n",
    "        \n",
    "    except: \n",
    "        df.to_csv('test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "https://news.mb.com.ph/tag/ncov/page1/\n",
      "https://news.mb.com.ph/2020/03/15/medical-practitioner-is-2nd-confirmed-covid-19-case-in-cavite/ stopped latest\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:112: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "get_mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('m_times_articles.csv', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df[0].append(article_list).reset_index(drop = True).to_csv('test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
